---
# Kubernetes Job Template for Experiment 1 (Text Generation via vLLM)
#
# Experiment 1 uses vLLM API for text generation:
# - Study 1 Exp 1: Raw text responses to knowledge attribution scenarios
# - Study 2 Exp 1: Politeness responses in constrained format
#
# Requirements:
# - vLLM deployment must be running
# - Connects to vLLM service endpoint
# - CPU-only job (no GPU needed)
#
# Usage:
#   1. Ensure vLLM deployment is running (e.g., vllm-gemma-2b)
#   2. Update MODEL_NAME, STUDY variables below
#   3. Apply: kubectl apply -f job-exp1-template.yaml

apiVersion: batch/v1
kind: Job
metadata:
  name: grace-study1-exp1-gemma2b
  namespace: lemn-lab
  labels:
    app: grace-experiment
    study: "1"
    experiment: "1"
    model: gemma-2b
spec:
  # Don't retry on failure - let user debug
  backoffLimit: 0

  # Clean up completed jobs after 1 hour
  ttlSecondsAfterFinished: 3600

  template:
    metadata:
      labels:
        app: grace-experiment
        study: "1"
        experiment: "1"
        model: gemma-2b
    spec:
      restartPolicy: Never

      containers:
      - name: experiment-runner
        image: gitlab-registry.nrp-nautilus.io/thmorton/grace-project/query-generator:latest
        imagePullPolicy: Always  # Always pull latest from registry

        command:
          - python3
          - /app/src/query_study1_exp1.py

        args:
          - --input=/app/data/study1.csv
          - --output=/data/results/study1_exp1_gemma2b_$(TIMESTAMP).csv
          - --endpoint=http://vllm-gemma-2b:8000
          - --model-name=gemma-2-2b-it

        env:
          - name: TIMESTAMP
            value: "20250119_000000"  # Set at Job creation time
          - name: PYTHONUNBUFFERED
            value: "1"  # Immediate log output
          - name: HF_HOME
            value: /models/.cache

        # CPU-only resources (no GPU needed - vLLM handles inference)
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "4800Mi"  # 120% of request
            cpu: "2400m"      # 120% of request

        volumeMounts:
          - name: results
            mountPath: /data/results

          - name: model-cache
            mountPath: /models

      volumes:
        - name: results
          persistentVolumeClaim:
            claimName: thomas-grace-results

        - name: model-cache
          persistentVolumeClaim:
            claimName: thomas-grace-model-cache
